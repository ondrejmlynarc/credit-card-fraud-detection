{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d68893dd-1d60-41c2-a4ec-83e789d43222",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "128cdeda-3112-499b-bb7e-41c3c84bed01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42179266-71e9-4f16-a9f0-b69c2037c0fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data Loading & preparing\n",
    "df = pd.read_parquet('../data/processed/creditcard_2023_processed.parquet')\n",
    "x = df.drop(['id','Class'], axis=1)\n",
    "y = df.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e12c513-1cba-4dd0-a843-4c3f77d51203",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------- Logistic Regression Validation Evaluation ---------\n",
      "Best parameters: {'C': 1}\n",
      "Model Accuracy: 0.9635\n",
      "Confusion Matrix:\n",
      " [[27867   564]\n",
      " [ 1514 26918]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96     28431\n",
      "           1       0.98      0.95      0.96     28432\n",
      "\n",
      "    accuracy                           0.96     56863\n",
      "   macro avg       0.96      0.96      0.96     56863\n",
      "weighted avg       0.96      0.96      0.96     56863\n",
      "\n",
      "Model saved to ../models\\logistic_regression.pkl\n",
      "Metrics saved to ../models\\logistic_regression_metrics.json\n",
      "\n",
      "------- Decision Tree Validation Evaluation ---------\n",
      "Best parameters: {'min_samples_split': 2, 'max_depth': None}\n",
      "Model Accuracy: 0.9695\n",
      "Confusion Matrix:\n",
      " [[27461   970]\n",
      " [  763 27669]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97     28431\n",
      "           1       0.97      0.97      0.97     28432\n",
      "\n",
      "    accuracy                           0.97     56863\n",
      "   macro avg       0.97      0.97      0.97     56863\n",
      "weighted avg       0.97      0.97      0.97     56863\n",
      "\n",
      "Model saved to ../models\\decision_tree.pkl\n",
      "Metrics saved to ../models\\decision_tree_metrics.json\n",
      "\n",
      "------- Random Forest Validation Evaluation ---------\n",
      "Best parameters: {'n_estimators': 50, 'min_samples_split': 2, 'max_depth': None}\n",
      "Model Accuracy: 0.9863\n",
      "Confusion Matrix:\n",
      " [[28305   126]\n",
      " [  655 27777]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     28431\n",
      "           1       1.00      0.98      0.99     28432\n",
      "\n",
      "    accuracy                           0.99     56863\n",
      "   macro avg       0.99      0.99      0.99     56863\n",
      "weighted avg       0.99      0.99      0.99     56863\n",
      "\n",
      "Model saved to ../models\\random_forest.pkl\n",
      "Metrics saved to ../models\\random_forest_metrics.json\n",
      "\n",
      "------- XGBoost Validation Evaluation ---------\n",
      "Best parameters: {'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.1}\n",
      "Model Accuracy: 0.9925\n",
      "Confusion Matrix:\n",
      " [[28256   175]\n",
      " [  253 28179]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     28431\n",
      "           1       0.99      0.99      0.99     28432\n",
      "\n",
      "    accuracy                           0.99     56863\n",
      "   macro avg       0.99      0.99      0.99     56863\n",
      "weighted avg       0.99      0.99      0.99     56863\n",
      "\n",
      "Model saved to ../models\\xgboost.pkl\n",
      "Metrics saved to ../models\\xgboost_metrics.json\n",
      "\n",
      "------- Support Vector Machine Validation Evaluation ---------\n",
      "Best parameters: {'kernel': 'rbf', 'gamma': 'scale', 'C': 10}\n",
      "Model Accuracy: 0.9916\n",
      "Confusion Matrix:\n",
      " [[28228   203]\n",
      " [  272 28160]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     28431\n",
      "           1       0.99      0.99      0.99     28432\n",
      "\n",
      "    accuracy                           0.99     56863\n",
      "   macro avg       0.99      0.99      0.99     56863\n",
      "weighted avg       0.99      0.99      0.99     56863\n",
      "\n",
      "Model saved to ../models\\support_vector_machine.pkl\n",
      "Metrics saved to ../models\\support_vector_machine_metrics.json\n",
      "\n",
      "All models trained, evaluated, and saved.\n"
     ]
    }
   ],
   "source": [
    "def save_model(model, model_name, folder_path='../models'):\n",
    "    # Ensure the folder path exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    \n",
    "    # Construct the file path\n",
    "    file_path = os.path.join(folder_path, f\"{model_name}.pkl\")\n",
    "    \n",
    "    # Save the model to the file\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "    \n",
    "    print(f\"Model saved to {file_path}\")\n",
    "\n",
    "def save_metrics(metrics, model_name, folder_path='../models'):\n",
    "    # Ensure the folder path exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    \n",
    "    # Construct the file path\n",
    "    file_path = os.path.join(folder_path, f\"{model_name}_metrics.json\")\n",
    "    \n",
    "    # Save the metrics to the JSON file\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(metrics, file, indent=4)\n",
    "    \n",
    "    print(f\"Metrics saved to {file_path}\")\n",
    "\n",
    "def evaluate_model(model_name, model, params, X_train, y_train, X_val, y_val, n_iter=10):\n",
    "    \"\"\"Train and evaluate a model with hyperparameter tuning using RandomizedSearchCV.\"\"\"\n",
    "    random_search = RandomizedSearchCV(model, params, cv=5, scoring='accuracy', n_jobs=-1, n_iter=n_iter, random_state=42)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = random_search.best_estimator_\n",
    "    y_val_pred = best_model.predict(X_val)\n",
    "    \n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    precision = precision_score(y_val, y_val_pred, average='weighted')\n",
    "    recall = recall_score(y_val, y_val_pred, average='weighted')\n",
    "    f1 = f1_score(y_val, y_val_pred, average='weighted')\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1\n",
    "    }\n",
    "    \n",
    "    print(f'\\n------- {model_name} Validation Evaluation ---------')\n",
    "    print(f'Best parameters: {random_search.best_params_}')\n",
    "    print(f'Model Accuracy: {accuracy:.4f}')\n",
    "    print('Confusion Matrix:\\n', confusion_matrix(y_val, y_val_pred))\n",
    "    print('Classification Report:\\n', classification_report(y_val, y_val_pred))\n",
    "    \n",
    "    # Save the model and metrics\n",
    "    save_model(best_model, model_name.replace(\" \", \"_\").lower())\n",
    "    save_metrics(metrics, model_name.replace(\" \", \"_\").lower())\n",
    "    \n",
    "    return best_model, metrics\n",
    "\n",
    "# preparing data for training, testing and validation\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = prepare_data(x, y)\n",
    "\n",
    "# models\n",
    "models = [\n",
    "    (\"Logistic Regression\", LogisticRegression(), {'C': [0.1, 1, 10]}),\n",
    "    (\"Decision Tree\", DecisionTreeClassifier(), {'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 5, 10]}),\n",
    "    (\"Random Forest\", RandomForestClassifier(), {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    }),\n",
    "    (\"XGBoost\", xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'), {\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2]\n",
    "    }),\n",
    "    (\"Support Vector Machine\", SVC(), {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    })\n",
    "]\n",
    "\n",
    "# train, evaluate, and save each model\n",
    "for model_name, model, params in models:\n",
    "    best_model, metrics = evaluate_model(model_name, model, params, X_train, y_train, X_val, y_val)\n",
    "\n",
    "print(\"\\nAll models trained, evaluated, and saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100d0e96-0ee5-4fea-8dc9-adc5e4c50ef1",
   "metadata": {},
   "source": [
    "# Based on the results:\n",
    "\n",
    "All models performed well, with accuracies ranging from 96.35% to 99.25%.\n",
    "XGBoost achieved the highest accuracy (99.25%), followed closely by SVM (99.16%) and Random Forest (98.57%).\n",
    "Decision Tree (97.03%) and Logistic Regression (96.35%) performed adequately but were outperformed by the more complex models.\n",
    "All models showed good balance between precision and recall for both classes.\n",
    "\n",
    "Taken together, XGBoost appears to be the most effective for this credit card fraud detection task, but model choice should also consider factors like interpretability and computational resources. For optimal fraud detection, XGBoost or SVM would be recommended based on these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408169da-0a61-427d-82c9-912865fc1bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
